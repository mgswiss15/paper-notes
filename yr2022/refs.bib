@unpublished{madhawa_graphnvp_2019,
    title = {{GraphNVP}: an Invertible Flow-based Model for Generating Molecular Graphs},
    url = {https://openreview.net/forum?id=ryxQ6T4YwB},
    shorttitle = {{GraphNVP}},
    abstract = {The first fully invertible flow-based generative model for molecular graphs is proposed.},
    author = {Madhawa, Kaushalya and Ishiguro, Katsuhiko and Nakago, Kosuke and Abe, Motoki},
    urldate = {2022-01-29},
    date = {2019-09-25},
    langid = {english},
    file = {Madhawa et al_2019_GraphNVP.pdf:/home/magda/Dropbox/Zot/Madhawa et al_2019_GraphNVP.pdf:application/pdf;Snapshot:/home/magda/Zotero fhws/storage/BYUCNH2V/forum.html:text/html},
}


@article{flam-shepherd_mpgvae_2021,
    title = {{MPGVAE}: improved generation of small organic molecules using message passing neural nets},
    volume = {2},
    issn = {2632-2153},
    url = {https://doi.org/10.1088/2632-2153/abf5b7},
    doi = {10.1088/2632-2153/abf5b7},
    shorttitle = {{MPGVAE}},
    abstract = {Graph generation is an extremely important task, as graphs are found throughout different areas of science and engineering. In this work, we focus on the modern equivalent of the Erdos–Rényi random graph model: the graph variational autoencoder ({GVAE}) (Simonovsky and Komodakis 2018 Int. Conf. on Artificial Neural Networks pp 412–22). This model assumes edges and nodes are independent in order to generate entire graphs at a time using a multi-layer perceptron decoder. As a result of these assumptions, {GVAE} has difficulty matching the training distribution and relies on an expensive graph matching procedure. We improve this class of models by building a message passing neural network into {GVAE}’s encoder and decoder. We demonstrate our model on the specific task of generating small organic molecules.},
    pages = {045010},
    number = {4},
    journaltitle = {Machine Learning: Science and Technology},
    shortjournal = {Mach. Learn.: Sci. Technol.},
    author = {Flam-Shepherd, Daniel and Wu, Tony C. and Aspuru-Guzik, Alan},
    urldate = {2022-01-29},
    date = {2021-07},
    langid = {english},
    note = {Publisher: {IOP} Publishing},
    file = {Flam-Shepherd et al_2021_MPGVAE.pdf:/home/magda/Dropbox/Zot/Flam-Shepherd et al_2021_MPGVAE.pdf:application/pdf},
}


@article{simonovsky_graphvae_2018,
    title = {{GraphVAE}: Towards Generation of Small Graphs Using Variational Autoencoders},
    url = {http://arxiv.org/abs/1802.03480},
    shorttitle = {{GraphVAE}},
    abstract = {Deep learning on graphs has become a popular research topic with many applications. However, past work has concentrated on learning graph embedding tasks, which is in contrast with advances in generative models for images and text. Is it possible to transfer this progress to the domain of graphs? We propose to sidestep hurdles associated with linearization of such discrete structures by having a decoder output a probabilistic fully-connected graph of a predefined maximum size directly at once. Our method is formulated as a variational autoencoder. We evaluate on the challenging task of molecule generation.},
    journaltitle = {{arXiv}:1802.03480 [cs]},
    author = {Simonovsky, Martin and Komodakis, Nikos},
    urldate = {2021-12-10},
    date = {2018-02-09},
    eprinttype = {arxiv},
    eprint = {1802.03480},
    file = {Simonovsky_Komodakis_2018_GraphVAE.pdf:/home/magda/Dropbox/Zot/Simonovsky_Komodakis_2018_GraphVAE.pdf:application/pdf;arXiv.org Snapshot:/home/magda/Zotero fhws/storage/S3BB5YEE/1802.html:text/html},
}


@inproceedings{yao_federated_2022,
    title = {Federated multi-target domain adaptation},
    pages = {1424--1433},
    booktitle = {Proceedings of the {IEEE}/{CVF} Winter Conference on Applications of Computer Vision},
    author = {Yao, Chun-Han and Gong, Boqing and Qi, Hang and Cui, Yin and Zhu, Yukun and Yang, Ming-Hsuan},
    date = {2022},
    file = {Yao et al_2022_Federated multi-target domain adaptation.pdf:/home/magda/Dropbox/Zot/Yao et al_2022_Federated multi-target domain adaptation.pdf:application/pdf},
}

