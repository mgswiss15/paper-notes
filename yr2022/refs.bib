@unpublished{madhawa_graphnvp_2019,
    title = {{GraphNVP}: an Invertible Flow-based Model for Generating Molecular Graphs},
    url = {https://openreview.net/forum?id=ryxQ6T4YwB},
    shorttitle = {{GraphNVP}},
    abstract = {The first fully invertible flow-based generative model for molecular graphs is proposed.},
    author = {Madhawa, Kaushalya and Ishiguro, Katsuhiko and Nakago, Kosuke and Abe, Motoki},
    urldate = {2022-01-29},
    date = {2019-09-25},
    langid = {english},
    file = {Madhawa et al_2019_GraphNVP.pdf:/home/magda/Dropbox/Zot/Madhawa et al_2019_GraphNVP.pdf:application/pdf;Snapshot:/home/magda/Zotero fhws/storage/BYUCNH2V/forum.html:text/html},
}

@article{flam-shepherd_mpgvae_2021,
    title = {{MPGVAE}: improved generation of small organic molecules using message passing neural nets},
    volume = {2},
    issn = {2632-2153},
    url = {https://doi.org/10.1088/2632-2153/abf5b7},
    doi = {10.1088/2632-2153/abf5b7},
    shorttitle = {{MPGVAE}},
    abstract = {Graph generation is an extremely important task, as graphs are found throughout different areas of science and engineering. In this work, we focus on the modern equivalent of the Erdos–Rényi random graph model: the graph variational autoencoder ({GVAE}) (Simonovsky and Komodakis 2018 Int. Conf. on Artificial Neural Networks pp 412–22). This model assumes edges and nodes are independent in order to generate entire graphs at a time using a multi-layer perceptron decoder. As a result of these assumptions, {GVAE} has difficulty matching the training distribution and relies on an expensive graph matching procedure. We improve this class of models by building a message passing neural network into {GVAE}’s encoder and decoder. We demonstrate our model on the specific task of generating small organic molecules.},
    pages = {045010},
    number = {4},
    journaltitle = {Machine Learning: Science and Technology},
    shortjournal = {Mach. Learn.: Sci. Technol.},
    author = {Flam-Shepherd, Daniel and Wu, Tony C. and Aspuru-Guzik, Alan},
    urldate = {2022-01-29},
    date = {2021-07},
    langid = {english},
    note = {Publisher: {IOP} Publishing},
    file = {Flam-Shepherd et al_2021_MPGVAE.pdf:/home/magda/Dropbox/Zot/Flam-Shepherd et al_2021_MPGVAE.pdf:application/pdf},
}

@article{simonovsky_graphvae_2018,
    title = {{GraphVAE}: Towards Generation of Small Graphs Using Variational Autoencoders},
    url = {http://arxiv.org/abs/1802.03480},
    shorttitle = {{GraphVAE}},
    abstract = {Deep learning on graphs has become a popular research topic with many applications. However, past work has concentrated on learning graph embedding tasks, which is in contrast with advances in generative models for images and text. Is it possible to transfer this progress to the domain of graphs? We propose to sidestep hurdles associated with linearization of such discrete structures by having a decoder output a probabilistic fully-connected graph of a predefined maximum size directly at once. Our method is formulated as a variational autoencoder. We evaluate on the challenging task of molecule generation.},
    journaltitle = {{arXiv}:1802.03480 [cs]},
    author = {Simonovsky, Martin and Komodakis, Nikos},
    urldate = {2021-12-10},
    date = {2018-02-09},
    eprinttype = {arxiv},
    eprint = {1802.03480},
    file = {Simonovsky_Komodakis_2018_GraphVAE.pdf:/home/magda/Dropbox/Zot/Simonovsky_Komodakis_2018_GraphVAE.pdf:application/pdf;arXiv.org Snapshot:/home/magda/Zotero fhws/storage/S3BB5YEE/1802.html:text/html},
}

@inproceedings{yao_federated_2022,
    title = {Federated multi-target domain adaptation},
    pages = {1424--1433},
    booktitle = {Proceedings of the {IEEE}/{CVF} Winter Conference on Applications of Computer Vision},
    author = {Yao, Chun-Han and Gong, Boqing and Qi, Hang and Cui, Yin and Zhu, Yukun and Yang, Ming-Hsuan},
    date = {2022},
    file = {Yao et al_2022_Federated multi-target domain adaptation.pdf:/home/magda/Dropbox/Zot/Yao et al_2022_Federated multi-target domain adaptation.pdf:application/pdf},
}

@inproceedings{ho_denoising_2020,
    title = {Denoising Diffusion Probabilistic Models},
    volume = {33},
    url = {https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf},
    pages = {6840--6851},
    booktitle = {Advances in Neural Information Processing Systems},
    publisher = {Curran Associates, Inc.},
    author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
    editor = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M. F. and Lin, H.},
    date = {2020},
    file = {Ho et al_2020_Denoising Diffusion Probabilistic Models.pdf:/home/magda/Dropbox/Zot/Ho et al_2020_Denoising Diffusion Probabilistic Models.pdf:application/pdf;Ho et al_2020_Denoising Diffusion Probabilistic Models.pdf:/home/magda/Dropbox/Zot/Ho et al_2020_Denoising Diffusion Probabilistic Models2.pdf:application/pdf},
}

@article{phoo_self-training_2021,
    title = {Self-training for Few-shot Transfer Across Extreme Task Differences},
    url = {http://arxiv.org/abs/2010.07734},
    abstract = {Most few-shot learning techniques are pre-trained on a large, labeled "base dataset". In problem domains where such large labeled datasets are not available for pre-training (e.g., X-ray, satellite images), one must resort to pre-training in a different "source" problem domain (e.g., {ImageNet}), which can be very different from the desired target task. Traditional few-shot and transfer learning techniques fail in the presence of such extreme differences between the source and target tasks. In this paper, we present a simple and effective solution to tackle this extreme domain gap: self-training a source domain representation on unlabeled data from the target domain. We show that this improves one-shot performance on the target domain by 2.9 points on average on the challenging {BSCD}-{FSL} benchmark consisting of datasets from multiple domains. Our code is available at https://github.com/cpphoo/{STARTUP}.},
    journaltitle = {{arXiv}:2010.07734 [cs]},
    author = {Phoo, Cheng Perng and Hariharan, Bharath},
    urldate = {2022-02-13},
    date = {2021-03-17},
    eprinttype = {arxiv},
    eprint = {2010.07734},
    keywords = {read, \_tablet},
    file = {Phoo_Hariharan_2021_Self-training for Few-shot Transfer Across Extreme Task Differences.pdf:/home/magda/Dropbox/Zot/Phoo_Hariharan_2021_Self-training for Few-shot Transfer Across Extreme Task Differences.pdf:application/pdf;arXiv.org Snapshot:/home/magda/Zotero fhws/storage/B5CHAY37/2010.html:text/html},
}

@article{song_generative_2020,
    title = {Generative Modeling by Estimating Gradients of the Data Distribution},
    url = {http://arxiv.org/abs/1907.05600},
    abstract = {We introduce a new generative model where samples are produced via Langevin dynamics using gradients of the data distribution estimated with score matching. Because gradients can be ill-defined and hard to estimate when the data resides on low-dimensional manifolds, we perturb the data with different levels of Gaussian noise, and jointly estimate the corresponding scores, i.e., the vector fields of gradients of the perturbed data distribution for all noise levels. For sampling, we propose an annealed Langevin dynamics where we use gradients corresponding to gradually decreasing noise levels as the sampling process gets closer to the data manifold. Our framework allows flexible model architectures, requires no sampling during training or the use of adversarial methods, and provides a learning objective that can be used for principled model comparisons. Our models produce samples comparable to {GANs} on {MNIST}, {CelebA} and {CIFAR}-10 datasets, achieving a new state-of-the-art inception score of 8.87 on {CIFAR}-10. Additionally, we demonstrate that our models learn effective representations via image inpainting experiments.},
    journaltitle = {{arXiv}:1907.05600 [cs, stat]},
    author = {Song, Yang and Ermon, Stefano},
    urldate = {2022-01-27},
    date = {2020-10-10},
    eprinttype = {arxiv},
    eprint = {1907.05600},
    keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {arXiv.org Snapshot:/home/magda/Zotero fhws/storage/N9TS2277/1907.html:text/html;Song_Ermon_2020_Generative Modeling by Estimating Gradients of the Data Distribution.pdf:/home/magda/Dropbox/Zot/Song_Ermon_2020_Generative Modeling by Estimating Gradients of the Data Distribution.pdf:application/pdf},
}

@article{welling_bayesian_2011,
    title = {Bayesian Learning via Stochastic Gradient Langevin Dynamics},
    abstract = {In this paper we propose a new framework for learning from large scale datasets based on iterative learning from small mini-batches. By adding the right amount of noise to a standard stochastic gradient optimization algorithm we show that the iterates will converge to samples from the true posterior distribution as we anneal the stepsize. This seamless transition between optimization and Bayesian posterior sampling provides an inbuilt protection against overﬁtting. We also propose a practical method for Monte Carlo estimates of posterior statistics which monitors a “sampling threshold” and collects samples after it has been surpassed. We apply the method to three models: a mixture of Gaussians, logistic regression and {ICA} with natural gradients.},
    pages = {8},
    author = {Welling, Max and Teh, Yee Whye},
    date = {2011},
    langid = {english},
    keywords = {\_tablet},
    file = {Welling_Teh_Bayesian Learning via Stochastic Gradient Langevin Dynamics.pdf:/home/magda/Dropbox/Zot/Welling_Teh_Bayesian Learning via Stochastic Gradient Langevin Dynamics.pdf:application/pdf},
}

@article{hyvarinen_estimation_2005,
    title = {Estimation of Non-Normalized Statistical Models by Score Matching},
    abstract = {One often wants to estimate statistical models where the probability density function is known only up to a multiplicative normalization constant. Typically, one then has to resort to Markov Chain Monte Carlo methods, or approximations of the normalization constant. Here, we propose that such models can be estimated by minimizing the expected squared distance between the gradient of the log-density given by the model and the gradient of the log-density of the observed data. While the estimation of the gradient of log-density function is, in principle, a very diﬃcult non-parametric problem, we prove a surprising result that gives a simple formula for this objective function. The density function of the observed data does not appear in this formula, which simpliﬁes to a sample average of a sum of some derivatives of the log-density given by the model. The validity of the method is demonstrated on multivariate Gaussian and independent component analysis models, and by estimating an overcomplete ﬁlter set for natural image data.},
    pages = {15},
    author = {Hyvarinen, Aapo},
    date = {2005},
    langid = {english},
    keywords = {skimmed},
    file = {Hyvarinen_Estimation of Non-Normalized Statistical Models by Score Matching.pdf:/home/magda/Dropbox/Zot/Hyvarinen_Estimation of Non-Normalized Statistical Models by Score Matching.pdf:application/pdf},
}

@article{vincent_connection_2011,
    title = {A Connection Between Score Matching and Denoising Autoencoders},
    volume = {23},
    issn = {0899-7667},
    doi = {10.1162/NECO_a_00142},
    abstract = {Denoising autoencoders have been previously shown to be competitive alternatives to restricted Boltzmann machines for unsupervised pretraining of each layer of a deep architecture. We show that a simple denoising autoencoder training criterion is equivalent to matching the score (with respect to the data) of a specific energy-based model to that of a nonparametric Parzen density estimator of the data. This yields several useful insights. It defines a proper probabilistic model for the denoising autoencoder technique, which makes it in principle possible to sample from them or rank examples by their energy. It suggests a different way to apply score matching that is related to learning to denoise and does not require computing second derivatives. It justifies the use of tied weights between the encoder and decoder and suggests ways to extend the success of denoising autoencoders to a larger family of energy-based models.},
    pages = {1661--1674},
    number = {7},
    journaltitle = {Neural Computation},
    author = {Vincent, Pascal},
    date = {2011-07},
    note = {Conference Name: Neural Computation},
    keywords = {skimmed},
    file = {Vincent_2011_A Connection Between Score Matching and Denoising Autoencoders.pdf:/home/magda/Dropbox/Zot/Vincent_2011_A Connection Between Score Matching and Denoising Autoencoders.pdf:application/pdf;IEEE Xplore Abstract Record:/home/magda/Zotero/storage/A7GDR57A/6795935.html:text/html},
}

@article{wallace_extending_2020,
    title = {Extending and Analyzing Self-Supervised Learning Across Domains},
    url = {http://arxiv.org/abs/2004.11992},
    abstract = {Self-supervised representation learning has achieved impressive results in recent years, with experiments primarily coming on {ImageNet} or other similarly large internet imagery datasets. There has been little to no work with these methods on other smaller domains, such as satellite, textural, or biological imagery. We experiment with several popular methods on an unprecedented variety of domains. We discover, among other findings, that Rotation is by far the most semantically meaningful task, with much of the performance of Jigsaw and Instance Discrimination being attributable to the nature of their induced distribution rather than semantic understanding. Additionally, there are several areas, such as fine-grain classification, where all tasks underperform. We quantitatively and qualitatively diagnose the reasons for these failures and successes via novel experiments studying pretext generalization, random labelings, and implicit dimensionality. Code and models are available at https://github.com/{BramSW}/Extending\_SSRL\_Across\_Domains/.},
    journaltitle = {{arXiv}:2004.11992 [cs, stat]},
    author = {Wallace, Bram and Hariharan, Bharath},
    urldate = {2022-02-15},
    date = {2020-08-17},
    eprinttype = {arxiv},
    eprint = {2004.11992},
    keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
    file = {Wallace_Hariharan_2020_Extending and Analyzing Self-Supervised Learning Across Domains.pdf:/home/magda/Dropbox/Zot/Wallace_Hariharan_2020_Extending and Analyzing Self-Supervised Learning Across Domains.pdf:application/pdf;arXiv.org Snapshot:/home/magda/Zotero fhws/storage/9ZHR5P5I/2004.html:text/html},
}

@article{guo_broader_2020,
    title = {A Broader Study of Cross-Domain Few-Shot Learning},
    url = {http://arxiv.org/abs/1912.07200},
    abstract = {Recent progress on few-shot learning largely relies on annotated data for meta-learning: base classes sampled from the same domain as the novel classes. However, in many applications, collecting data for meta-learning is infeasible or impossible. This leads to the cross-domain few-shot learning problem, where there is a large shift between base and novel class domains. While investigations of the cross-domain few-shot scenario exist, these works are limited to natural images that still contain a high degree of visual similarity. No work yet exists that examines few-shot learning across different imaging methods seen in real world scenarios, such as aerial and medical imaging. In this paper, we propose the Broader Study of Cross-Domain Few-Shot Learning ({BSCD}-{FSL}) benchmark, consisting of image data from a diverse assortment of image acquisition methods. This includes natural images, such as crop disease images, but additionally those that present with an increasing dissimilarity to natural images, such as satellite images, dermatology images, and radiology images. Extensive experiments on the proposed benchmark are performed to evaluate state-of-art meta-learning approaches, transfer learning approaches, and newer methods for cross-domain few-shot learning. The results demonstrate that state-of-art meta-learning methods are surprisingly outperformed by earlier meta-learning approaches, and all meta-learning methods underperform in relation to simple fine-tuning by 12.8\% average accuracy. Performance gains previously observed with methods specialized for cross-domain few-shot learning vanish in this more challenging benchmark. Finally, accuracy of all methods tend to correlate with dataset similarity to natural images, verifying the value of the benchmark to better represent the diversity of data seen in practice and guiding future research.},
    journaltitle = {{arXiv}:1912.07200 [cs]},
    author = {Guo, Yunhui and Codella, Noel C. and Karlinsky, Leonid and Codella, James V. and Smith, John R. and Saenko, Kate and Rosing, Tajana and Feris, Rogerio},
    urldate = {2022-02-15},
    date = {2020-07-17},
    eprinttype = {arxiv},
    eprint = {1912.07200},
    keywords = {benchmark, skimmed, survey},
    file = {Guo et al_2020_A Broader Study of Cross-Domain Few-Shot Learning.pdf:/home/magda/Dropbox/Zot/Guo et al_2020_A Broader Study of Cross-Domain Few-Shot Learning.pdf:application/pdf;arXiv.org Snapshot:/home/magda/Zotero fhws/storage/PLCC8TBI/1912.html:text/html},
}

@article{wallace_extending_2020,
    title = {Extending and Analyzing Self-Supervised Learning Across Domains},
    url = {http://arxiv.org/abs/2004.11992},
    abstract = {Self-supervised representation learning has achieved impressive results in recent years, with experiments primarily coming on {ImageNet} or other similarly large internet imagery datasets. There has been little to no work with these methods on other smaller domains, such as satellite, textural, or biological imagery. We experiment with several popular methods on an unprecedented variety of domains. We discover, among other findings, that Rotation is by far the most semantically meaningful task, with much of the performance of Jigsaw and Instance Discrimination being attributable to the nature of their induced distribution rather than semantic understanding. Additionally, there are several areas, such as fine-grain classification, where all tasks underperform. We quantitatively and qualitatively diagnose the reasons for these failures and successes via novel experiments studying pretext generalization, random labelings, and implicit dimensionality. Code and models are available at https://github.com/{BramSW}/Extending\_SSRL\_Across\_Domains/.},
    journaltitle = {{arXiv}:2004.11992 [cs, stat]},
    author = {Wallace, Bram and Hariharan, Bharath},
    urldate = {2022-02-15},
    date = {2020-08-17},
    eprinttype = {arxiv},
    eprint = {2004.11992},
    keywords = {skimmed},
    file = {Wallace_Hariharan_2020_Extending and Analyzing Self-Supervised Learning Across Domains.pdf:/home/magda/Dropbox/Zot/Wallace_Hariharan_2020_Extending and Analyzing Self-Supervised Learning Across Domains.pdf:application/pdf;arXiv.org Snapshot:/home/magda/Zotero fhws/storage/9ZHR5P5I/2004.html:text/html},
}

@article{chen_simple_2020,
    title = {A Simple Framework for Contrastive Learning of Visual Representations},
    url = {http://arxiv.org/abs/2002.05709},
    abstract = {This paper presents {SimCLR}: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on {ImageNet}. A linear classifier trained on self-supervised representations learned by {SimCLR} achieves 76.5\% top-1 accuracy, which is a 7\% relative improvement over previous state-of-the-art, matching the performance of a supervised {ResNet}-50. When fine-tuned on only 1\% of the labels, we achieve 85.8\% top-5 accuracy, outperforming {AlexNet} with 100X fewer labels.},
    journaltitle = {{arXiv}:2002.05709 [cs, stat]},
    author = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
    urldate = {2022-02-14},
    date = {2020-06-30},
    eprinttype = {arxiv},
    eprint = {2002.05709},
    keywords = {\_tablet, read},
    file = {Chen et al_2020_A Simple Framework for Contrastive Learning of Visual Representations.pdf:/home/magda/Dropbox/Zot/Chen et al_2020_A Simple Framework for Contrastive Learning of Visual Representations.pdf:application/pdf;arXiv.org Snapshot:/home/magda/Zotero fhws/storage/2J7F7BWK/2002.html:text/html},
}

@inproceedings{xie_self-training_2020,
    location = {Seattle, {WA}, {USA}},
    title = {Self-Training With Noisy Student Improves {ImageNet} Classification},
    isbn = {978-1-72817-168-5},
    url = {https://ieeexplore.ieee.org/document/9156610/},
    doi = {10.1109/CVPR42600.2020.01070},
    abstract = {We present a simple self-training method that achieves 88.4\% top-1 accuracy on {ImageNet}, which is 2.0\% better than the state-of-the-art model that requires 3.5B weakly labeled Instagram images. On robustness test sets, it improves {ImageNet}-A top-1 accuracy from 61.0\% to 83.7\%, reduces {ImageNet}-C mean corruption error from 45.7 to 28.3, and reduces {ImageNet}-P mean ﬂip rate from 27.8 to 12.2.},
    eventtitle = {2020 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
    pages = {10684--10695},
    booktitle = {2020 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
    publisher = {{IEEE}},
    author = {Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V.},
    urldate = {2022-02-14},
    date = {2020-06},
    langid = {english},
    keywords = {skimmed},
    file = {Xie et al_2020_Self-Training With Noisy Student Improves ImageNet Classification.pdf:/home/magda/Dropbox/Zot/Xie et al_2020_Self-Training With Noisy Student Improves ImageNet Classification.pdf:application/pdf},
}

@inproceedings{tolstikhin_mlp-mixer_2021,
    title = {{MLP}-Mixer: An all-{MLP} Architecture for Vision},
    url = {https://openreview.net/forum?id=EI2KOXKdnP},
    shorttitle = {{MLP}-Mixer},
    abstract = {{MLP}-Mixer is a new competitive architecture for computer vision that uses only basic matrix multiplication routines ({MLPs}).},
    eventtitle = {Advances in Neural Information Processing Systems},
    author = {Tolstikhin, Ilya and Houlsby, Neil and Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Unterthiner, Thomas and Yung, Jessica and Steiner, Andreas Peter and Keysers, Daniel and Uszkoreit, Jakob and Lucic, Mario and Dosovitskiy, Alexey},
    urldate = {2022-02-13},
    date = {2021-05-21},
    langid = {english},
    keywords = {{notesPending}},
    file = {Tolstikhin et al_2021_MLP-Mixer.pdf:/home/magda/Dropbox/Zot/Tolstikhin et al_2021_MLP-Mixer.pdf:application/pdf;Snapshot:/home/magda/Zotero/storage/QQS4D3L3/forum.html:text/html},
}